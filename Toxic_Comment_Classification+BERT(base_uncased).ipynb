{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification+BERT(base_uncased).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "744548f65df24e82b4dd626e2d89df09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_520ff3b38ebe442d94dcd40fe192c122",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c224d3ac1c44d76b72670ba1dd406b7",
              "IPY_MODEL_c1d73b1aede14c768a34023e9b8d062f"
            ]
          }
        },
        "520ff3b38ebe442d94dcd40fe192c122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c224d3ac1c44d76b72670ba1dd406b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3aed03852c8b4db4b5c59a9ed8f5c0e0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05bdf7adaaea4ab7ac8714f01a491039"
          }
        },
        "c1d73b1aede14c768a34023e9b8d062f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d8686ed8d584d9c94007ec87ad92639",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 957kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5edf5893c22445a0991b754094cc2b05"
          }
        },
        "3aed03852c8b4db4b5c59a9ed8f5c0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05bdf7adaaea4ab7ac8714f01a491039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d8686ed8d584d9c94007ec87ad92639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5edf5893c22445a0991b754094cc2b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49636b16a54e4db6a03ba25ab80862d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32b35786475b484c9933e89d847c9336",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0de0d35bc95a477a86d73b81d5b6b8f5",
              "IPY_MODEL_020229661e5c40d2a894f73d86222c2e"
            ]
          }
        },
        "32b35786475b484c9933e89d847c9336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0de0d35bc95a477a86d73b81d5b6b8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fb5c83616c6489e9cc9dbf1b7ca3779",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff3491cad8af4643af84c756d7d4049c"
          }
        },
        "020229661e5c40d2a894f73d86222c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa54ebbb9acd4d5bbfe632f83a02eb10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 3.17kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18e8420d9b8b4ddbb3a34ee60a002e9f"
          }
        },
        "1fb5c83616c6489e9cc9dbf1b7ca3779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff3491cad8af4643af84c756d7d4049c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa54ebbb9acd4d5bbfe632f83a02eb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18e8420d9b8b4ddbb3a34ee60a002e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "865ef605761448b3acbbf6b33c7224dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d16a8178fef43d397b41855ab21aeec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4e03612e21a4f0ab2f8146b81a93182",
              "IPY_MODEL_e67aa252d58e422fa12e798fbb9b1387"
            ]
          }
        },
        "5d16a8178fef43d397b41855ab21aeec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4e03612e21a4f0ab2f8146b81a93182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5382ddc62bd476292b1368b3bd55be9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44bd2a2fe9bb47199a2756a236895735"
          }
        },
        "e67aa252d58e422fa12e798fbb9b1387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95a60c6a8f814474a3f9b41d30ea4043",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 67.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_589c73b1bd254c8093ea52dce5eec117"
          }
        },
        "b5382ddc62bd476292b1368b3bd55be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44bd2a2fe9bb47199a2756a236895735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95a60c6a8f814474a3f9b41d30ea4043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "589c73b1bd254c8093ea52dce5eec117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvlG1jY5g5Bh",
        "colab_type": "text"
      },
      "source": [
        "##*Classifying Toxic Comments with BERT*\n",
        "By Nakshatra Singh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Nmcqb2hJB1",
        "colab_type": "text"
      },
      "source": [
        "This notebook will show you how to fine-tune BERT for *Toxic Comment Classification*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS_EM1zv0_w3",
        "colab_type": "text"
      },
      "source": [
        "##Using Google GPU for Training\n",
        "\n",
        "Google colab offers free GPUs and TPUs! Since we'll be training a large model it's best to take advantage of this (in this case we'll use GPU), otherwise training can take long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit -> Notebook Settings -> Hardware Accelerator -> (GPU)`\n",
        "\n",
        "Then run the following cell to confirm that a GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVCWcBkQ0SCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55e943ca-8757-4a6a-9b5f-2b7de57039d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Get the device GPU name \n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at : {}'.format(device_name)) \n",
        "else:\n",
        "  raise SystemError('GPU not found!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uktjD_KQhMDl",
        "colab_type": "text"
      },
      "source": [
        "In order for torch to use GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spy_ketchJsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96f4d936-ae80-4d6c-aa53-38be5f047f8c"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there is a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  # Tell pytorch to use the GPU\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  print('No GPU available, using CPU instead')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbHxaaF6i3ml",
        "colab_type": "text"
      },
      "source": [
        "###**1. Installing the Hugging Face library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmAN7qD16Ke",
        "colab_type": "text"
      },
      "source": [
        "Next, let's install the *`transformers`* package from Hugging Face which will give us a pytorch interface to work with BERT. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEBHmAXbinUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "b4c412cc-0c40-4674-e282-c87fdc081dd6"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a59ba33b14b6a84f57b0dd074d51774019ddd9d34eed17b338dba657e20f7f20\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InYFDknEjKX9",
        "colab_type": "text"
      },
      "source": [
        "###**2. Retrieve and Inspect Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3qifo6w2a7g",
        "colab_type": "text"
      },
      "source": [
        "Let's download the dataset which is uploaded on my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvosflVQjb4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3888cd84-de31-4a81-8b06-f70edd994601"
      },
      "source": [
        "!gdown --id 11Yk7Xh4iekxZM6yEwerfHicx0p5_JC7m "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11Yk7Xh4iekxZM6yEwerfHicx0p5_JC7m\n",
            "To: /content/train.csv\n",
            "68.8MB [00:00, 122MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pabcmFU-sLSD",
        "colab_type": "text"
      },
      "source": [
        "We'll use `pandas` to parse the csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NFjXms7jBCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "comments = pd.read_csv('/content/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYaOsqMtsWYM",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the first few rows of the table just to see what's in there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3nDedbHjtkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "42f87535-2349-4e05-a108-bf351e34a6a8"
      },
      "source": [
        "comments.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np2dLG4DzIP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "992705b4-4b40-40b1-a7e4-2d314807257f"
      },
      "source": [
        "comments.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1dnzACtsrRd",
        "colab_type": "text"
      },
      "source": [
        "Display some comments. Be prepared to see some terrible human behavior..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoht0tpjkxgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "31cca6dd-13ee-49d4-e9b2-5fe05dc109aa"
      },
      "source": [
        "import textwrap\n",
        "import random\n",
        "#wrap text to 100 characters.\n",
        "wrapper = textwrap.TextWrapper(width=100)\n",
        "\n",
        "#filter to just the 'toxic' comments.\n",
        "toxic_examples = comments['comment_text']\n",
        "\n",
        "#randomly choose some examples.\n",
        "for i in range(5):\n",
        "  j = random.choice(toxic_examples.index)\n",
        "\n",
        "  print('')\n",
        "  print(wrapper.fill(toxic_examples[j]))\n",
        "  print('') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\"Welcome to Wikipedia, the free encyclopedia! You don't have to log in to read or edit articles on\n",
            "Wikipedia, but creating an account is quick, free and non-intrusive, requires no personal\n",
            "information, and gives you many benefits, including: The use of a username of your choice, provided\n",
            "that it is appropriate. The ability to view all your contributions via a \"\"My contributions\"\" link.\n",
            "Your own user page. Your own talk page which, if you choose, also allows users to send you messages\n",
            "without knowing your e-mail address. The use of your own personal watchlist to which you can add\n",
            "articles that interest you. The ability to start new pages. The ability to rename pages. The ability\n",
            "to upload images. The ability to customize the appearance and behavior of the website. The\n",
            "eligibility to become an administrator. The right to be heard in votes and elections. Your IP\n",
            "address will no longer be visible to other users.  We hope you enjoy your time here on Wikipedia and\n",
            "that you choose to become a Wikipedian by creating an account. Feel free to ask me any questions you\n",
            "may have on my talk page. By the way, you should sign your name to your posts and comments with\n",
            "~~~~.  (Dark Mark) \"\n",
            "\n",
            "\n",
            "AWNB updater   fix the apostrophe problem (on the deletion sorting page) for ye olde bot.\n",
            "207.6.245.26\n",
            "\n",
            "\n",
            "\" Ack, you didn't do it right, it says I'm nominating myself, and it points back to my FIRST RfA.  •\n",
            "(Broken clamshells•Otter chirps•Review?) \"\n",
            "\n",
            "\n",
            "User page Hey I'm real sorry. I saw red link and assumed talk page, no offence was intended.\n",
            "\n",
            "\n",
            "Hey!   I apologized!   But the way you were talking was kind of deceptive...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZwdfLASj3I0",
        "colab_type": "text"
      },
      "source": [
        "### **3. BERT Input Length Limitation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7R1XkyVkAFD",
        "colab_type": "text"
      },
      "source": [
        "BERT has a *maximum input length* of 512 tokens. In this section, we'll look at how this limitation affects us in practice, and some possible approaches for addressing it.\n",
        "\n",
        "First, we'll load the BERT tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qHXLa2kj2iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "744548f65df24e82b4dd626e2d89df09",
            "520ff3b38ebe442d94dcd40fe192c122",
            "4c224d3ac1c44d76b72670ba1dd406b7",
            "c1d73b1aede14c768a34023e9b8d062f",
            "3aed03852c8b4db4b5c59a9ed8f5c0e0",
            "05bdf7adaaea4ab7ac8714f01a491039",
            "6d8686ed8d584d9c94007ec87ad92639",
            "5edf5893c22445a0991b754094cc2b05"
          ]
        },
        "outputId": "f03ba6c9-0748-4135-f36f-f9bf73d56b25"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT Tokenizer\n",
        "print('Loading BERT Tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT Tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "744548f65df24e82b4dd626e2d89df09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdfSIeBJlsGR",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the first comment in the dataset looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkz0TGEYj2mA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b51ba566-f3ea-4cd1-91b1-122345ea0b00"
      },
      "source": [
        "# Retrieve the text of the first comment.\n",
        "text = comments.iloc[0].comment_text\n",
        "\n",
        "# Run the tokenizer to count up the number of tokens. The tokenizer will split\n",
        "# the text into words, punctuations, and subwords as needed.\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print('Comment 0 contains {:,} WordPiece tokens.'.format(len(tokens)))\n",
        "print('\\nOriginal comment text:\\n')\n",
        "print(wrapper.fill(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 0 contains 66 WordPiece tokens.\n",
            "\n",
            "Original comment text:\n",
            "\n",
            "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't\n",
            "vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove\n",
            "the template from the talk page since I'm retired now.89.205.38.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUtb_tWqo84O",
        "colab_type": "text"
      },
      "source": [
        "For our intuitive understanding we will only take 30000 samples. I tried training the model with the whole dataset, it spits an error: `CUDA out of memory`. So we'll be taking 30000 examples. I believe you can increase this to 70000 at max, if not just try a lower number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKCtI4n_y0ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8246c79b-c892-4c97-c3ea-062f2edde6e5"
      },
      "source": [
        "comments = comments.loc[:30000,:]\n",
        "comments.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30001, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrg4QPUunzgr",
        "colab_type": "text"
      },
      "source": [
        "###**3.1 Strategies for Longer Text**\n",
        "\n",
        "Key points:\n",
        "- There is no obvious solution, but we'll cover a number of ideas to try.\n",
        "- Looking at the statistics of your dataset should help when choosing your strategy\n",
        "\n",
        "There was a [*paper published*](https://arxiv.org/abs/1905.05583) recently that investigated this problem and experimented with a few approaches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaPvnrEEqI_S",
        "colab_type": "text"
      },
      "source": [
        "###3.1.1 Truncation\n",
        "The simplest approach is to drop some of the tokens and hope that the remaining text is enough to perform the task well.\n",
        "\n",
        "You can drop tokens:\n",
        "- From the beginning of the text.\n",
        "- At the end of the text.\n",
        "- In the middle of the text.\n",
        "\n",
        "In the above paper, their experiment on the IMDb movie review dataset showed that keeping the first 128 tokens and the last 382 tokens performed the best. (Note: This adds to 510 tokens, leaving room for the special `[CLS]` and `[SEP]` tokens that we have to append in the beginning and end of the text respectively.\n",
        "\n",
        "*Visit section 5.3 in the paper for more details.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zb0W7_br-5K",
        "colab_type": "text"
      },
      "source": [
        "###3.1.2 Chunking\n",
        "\n",
        "Another approach attempted by the authors would be to divide the text into 512 token chunks and generate embeddings for these chunks seperately.\n",
        "\n",
        "The authors of the paper combined the embeddings for the differnt chunks before performing the final classification. They tried several *pooling* strategies, such as averaging the embeddings together. None of these methods outperformed the simple truncation approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXuk-VLVt3Is",
        "colab_type": "text"
      },
      "source": [
        "###3.1.3 Comment Length Distribution\n",
        "\n",
        "To decide on a truncation strategy for this dataset, let's first look at the distribution comment lengths.\n",
        "\n",
        "To do this, our first step is to tokenize all of the comments in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4DxtrL0ub20",
        "colab_type": "text"
      },
      "source": [
        "###**Tokenize All Comments**\n",
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentance into tokens.\n",
        "2. Add special tokens `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "In order to explore the distribution of the comment lengths, we will not perform any truncation here. *`Unfortunately, this results in the tokenizer spitting out a warning for every comment that's longer than 512 tokens`*. We'll just have to ignore this for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFRFQLdxj2kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ef7cd39-44e3-4130-8caa-983003dbafb3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Tokenize all the sentences and map the tokens to their word IDs.\n",
        "input_ids = [] \n",
        "\n",
        "# Record the length of each sequence (after truncating to 512).\n",
        "lengths = []\n",
        "\n",
        "# For every sentence...\n",
        "for sen in comments.comment_text:\n",
        "\n",
        "  # 'encode' will:\n",
        "  # (1) Tokenize the sentence.\n",
        "  # (2) Prepend the [CLS] token to the start.\n",
        "  # (3) Append the [SEP] token to the end.\n",
        "  # (4) Map tokens to their IDs.\n",
        "  encode_sent = tokenizer.encode(\n",
        "      sen,                       # Sentence to encode.\n",
        "      add_special_tokens = True, # Add [CLS] and [SEP].\n",
        "      #max_length = 512,         # Truncate all sentences to 512.\n",
        "      #return_tensor = 'pt       # Return pytorch tensor.\n",
        "  )\n",
        " \n",
        "  # Add the encoded sentences to the list.\n",
        "  input_ids.append(encode_sent)\n",
        "\n",
        "  # Record the truncated length.\n",
        "  lengths.append(len(encode_sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (980 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2499 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqa7o6OWxkOu",
        "colab_type": "text"
      },
      "source": [
        "Before we continue, let's also retrieve the comment labels, and check out the class distribution for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTv7Vnypj2fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the labels from the dataframe and convert them to ints.\n",
        "labels = comments.toxic.to_numpy().astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5B2xEBo0vKt",
        "colab_type": "text"
      },
      "source": [
        "Let's grab some quick statistics- what are min, max and median comment lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIh5rPQ942y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "876eb3c2-e8a1-4e2a-f9dd-bba847fd9278"
      },
      "source": [
        "print('    Min Length: {:,} tokens'.format(min(lengths)))\n",
        "print('    Max Length: {:,} tokens'.format(max(lengths)))\n",
        "print(' Median Length: {:,} tokens'.format(np.median(lengths)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Min Length: 4 tokens\n",
            "    Max Length: 2,501 tokens\n",
            " Median Length: 52.0 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH5Hl5bN0-RN",
        "colab_type": "text"
      },
      "source": [
        "To further analysis it, let's plot the distribution. To keep the scale of x-axis reasonable, we'll clip the lengths to 512."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9IBw7mdjLV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "cdef904b-190f-4a49-b2ec-b8fee69ca2bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')  \n",
        "\n",
        "# Increase the plot size and font size\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "\n",
        "# Truncate any comment lengths greater than 512\n",
        "lengths = [min(l, 512) for l in lengths]\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(lengths, kde=False, rug=False)\n",
        "\n",
        "# Label the plot.\n",
        "plt.title('Comment Lengths')\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel('No.of Comments');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRdplZZb57B5",
        "colab_type": "text"
      },
      "source": [
        "Clearly, most of the comments are \"short\", and there is a long tail of larger comments.\n",
        "\n",
        "Just how many examples run into the 512 token limit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8zhPC_-jLni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a24e3031-be0b-4a19-d7e7-7754b462897a"
      },
      "source": [
        "# Count the number of sentences that have been truncated to 512 tokens.\n",
        "num_truncated = lengths.count(512)\n",
        "\n",
        "# Compare this to the total number of training sentences.\n",
        "num_sentences = len(lengths)\n",
        "\n",
        "pcent = float(num_truncated) / float(num_sentences)\n",
        "\n",
        "print('{:,} of {:,} sentences ({:.1%}) in the training set are longer than 512 tokens'.format(num_truncated, num_sentences, pcent))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "664 of 30,001 sentences (2.2%) in the training set are longer than 512 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnI9Vo349bq3",
        "colab_type": "text"
      },
      "source": [
        "###**4. Pad and Truncate the Comments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Nx_z-o9phk",
        "colab_type": "text"
      },
      "source": [
        "I think it seems safe to truncate our comments to 512 tokens.\n",
        "\n",
        "Not only that, I can think we can get away with an even shorter length to speed things up. i've picked the max length to 128, since this is around the elbow of the distribution.\n",
        "\n",
        "We can also try longer lengths to see how much this improves the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY9q8hGojLuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll borrow the pad sequences utility fucntion to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the required sentence length.\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIMD2YIX_GKc",
        "colab_type": "text"
      },
      "source": [
        "###**5. Attention Masks**\n",
        "\n",
        "The attention mask simply makes it explicit which tokens are actual versus which are paddings.\n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a ID is taken 0, then it's a padding, and otherwise it is a real token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTfWNn_Ezjy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks.\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "  # create the attention mask.\n",
        "  # - if token ID is 0, then it's padding, so set the mask to 0.\n",
        "  # - if token IS > 0, then it's a real token, so set the mask to 1.\n",
        "\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  # Store the attention masks for the sentences.\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvp8pjhxAVVk",
        "colab_type": "text"
      },
      "source": [
        "###**6. Final Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1OflRWZAl62",
        "colab_type": "text"
      },
      "source": [
        "1) Divide up our dataset to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlN76iTdzjsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2020, test_size=0.1)\n",
        "\n",
        "# Do the same for masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2021, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iUAVBufBPQr",
        "colab_type": "text"
      },
      "source": [
        "2) Our model exports Pytroch tensors rather than numpy.ndarrays, so let's convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHEx02qjLqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all our inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcZzYx7CKJl",
        "colab_type": "text"
      },
      "source": [
        "3) We'll also create an iterator for our dataset using torch DataLoader class. This helps us save memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXnbTeYljLkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The dataloader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size) \n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhVnJ9bUE_-d",
        "colab_type": "text"
      },
      "source": [
        "###**7. BERT Fine-Tuning**\n",
        "\n",
        "#### Train our Classification Model:\n",
        "\n",
        "Now that our input data is properly formatted, it's time to fine-tune the BERT model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_1-B_qFcAV",
        "colab_type": "text"
      },
      "source": [
        "###*`7.1 BERTForSequenceClassification`*\n",
        "\n",
        "For this task, we firstly want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model end-to-end is well-suited for our task.\n",
        "\n",
        "Thankfully, the huggingFace pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Here is the current list of classes provided for fine-tuning:\n",
        "- BertModel\n",
        "- BertForPretraining\n",
        "- BertForMaskedLM\n",
        "- BertForNextSentencePrediction\n",
        "- BertForSequenceClassification\n",
        "- BertForTokenClassification\n",
        "- BertForQuestionAnswering\n",
        "\n",
        "We'll use **BertForSequenceClassification**. *`This is the simple BERT model with an added single linear layer on top for classification that we will use as a sentence classifier`*. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "OK! Let's load the BERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoabBoZAjLS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "49636b16a54e4db6a03ba25ab80862d1",
            "32b35786475b484c9933e89d847c9336",
            "0de0d35bc95a477a86d73b81d5b6b8f5",
            "020229661e5c40d2a894f73d86222c2e",
            "1fb5c83616c6489e9cc9dbf1b7ca3779",
            "ff3491cad8af4643af84c756d7d4049c",
            "fa54ebbb9acd4d5bbfe632f83a02eb10",
            "18e8420d9b8b4ddbb3a34ee60a002e9f",
            "865ef605761448b3acbbf6b33c7224dc",
            "5d16a8178fef43d397b41855ab21aeec",
            "e4e03612e21a4f0ab2f8146b81a93182",
            "e67aa252d58e422fa12e798fbb9b1387",
            "b5382ddc62bd476292b1368b3bd55be9",
            "44bd2a2fe9bb47199a2756a236895735",
            "95a60c6a8f814474a3f9b41d30ea4043",
            "589c73b1bd254c8093ea52dce5eec117"
          ]
        },
        "outputId": "b33b293a-98e0-499e-ebb9-ff8eb7527fdd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', # Use the 24 layer BERT model, with an uncased vocab.\n",
        "                                                      num_labels =2, # The number of output labels --2 for binary classification, you can\n",
        "                                                                     # increase this for multiclass tasks. \n",
        "                                                      output_attentions = False,    # whether the model returns attention weights.\n",
        "                                                      output_hidden_states = False) # whether the model returns all hidden-states.\n",
        "model.cuda() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49636b16a54e4db6a03ba25ab80862d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "865ef605761448b3acbbf6b33c7224dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8TCEwLELypy",
        "colab_type": "text"
      },
      "source": [
        "###*`7.2 Optimizers and Learning Rate Scheduler`*\n",
        "\n",
        "Now that we have our model loaded we need to grab the training hyperparamters from within the stored model.\n",
        "\n",
        "For the purpose of fine-tuning, the authors have recommended choosing from the following values:\n",
        "- Batch size: 16, 32 (we chose 32 when creating the dataloader)\n",
        "- Learning Rate (Adam): 5e-5, 3e-5, 2e-5 (we'll use 2e-5)\n",
        "- Number of Epochs: 2, 3, 4 (we'll use 4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVaLetO9Ba4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from huggingface library (as opposed to pytorch).\n",
        "# I believe the 'W' stands for weight decay fix.\n",
        "\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDLVeq86BbDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVw6U0JFOrkQ",
        "colab_type": "text"
      },
      "source": [
        "###*`7.3 Training Loop`*\n",
        "\n",
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ9mKsVIBbF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmhQihnLPRaa",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for formatting elapsed time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhtMInBJOqcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYU48koVP0u4",
        "colab_type": "text"
      },
      "source": [
        "We are ready to kickstart the training!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6zVK76Ba-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dfcd96b-c412-4442-b92c-21c174c3db05"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make it reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "  print(\"\")\n",
        "  print('========== EPOCH {:} / {:} =========='.format(epoch_i + 1, epochs))\n",
        "  print('Training.....')\n",
        "\n",
        "  #Measure how long the training epoch took.\n",
        "  t0 = time.time() \n",
        "\n",
        "  #Reset the total loss for this epoch.\n",
        "  total_loss = 0\n",
        "  \n",
        "  #Dont be mislead the train cll just changes the mode.\n",
        "  model.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    if step%100 == 0 and not step ==0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      print('  Batch {:>5,} of {:>5,}  Elasped : {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    # Unpack this training batch from our dataloader.\n",
        "    # As we unpack the batch, we'll also copy each copy to the GPU using the \n",
        "    # .to methdod.\n",
        "\n",
        "    # Batch contains three pytorch tensors:\n",
        "    # [0]: input_ids\n",
        "    # [1]: attention_masks\n",
        "    # [2]: labels\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. Pytorch doesn't do this automatically because\n",
        "    # accumilating the gradients is \"convenient while training RNNs\"\n",
        "\n",
        "    model.zero_grad() \n",
        "\n",
        "    # perform a forward pass (evaluate the model on this training batch).\n",
        "    # This will return the loss (rather than model output) because we have \n",
        "    # provided the labels.\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask,\n",
        "                      labels = b_labels)  \n",
        "      \n",
        "    #The call to 'model' always returns a tuple, so we need to pull the loss \n",
        "    # value out of the tuple.\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can \n",
        "    # calculate the average loss at the end. 'Loss' is a tensor containing a\n",
        "    # single value; the '.item()' function just returns the python value\n",
        "    # from the tensor.\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # perform a backward pass to calculate the gradients.\n",
        "    loss.backward() \n",
        "\n",
        "    # clip the norm of the gradients to 1.0.\n",
        "    # this is to help prevent the 'exploding gradient' problem.\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the 'update rule' -- how the parameters\n",
        "    # are modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #update learning rate.\n",
        "    scheduler.step()\n",
        "\n",
        "  # calculate the average loss over the training data.\n",
        "  avg_train_loss = total_loss/ len(train_dataloader)\n",
        "\n",
        "  # store the loss values for plotting the learning curve.\n",
        "  loss_values.append(avg_train_loss)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training Epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  # =====================================\n",
        "  #             Validation\n",
        "  # =====================================\n",
        "  # After the completion of each training epoch, measure our performance on\n",
        "  # our validation set.\n",
        "\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation.....\")\n",
        "\n",
        "  #Measure how long the validation epoch took.\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Putting the model in evaluation mode --dropout layers behave differntly \n",
        "  #during evaluation.\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables.\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch.\n",
        "  for batch in validation_dataloader:\n",
        "\n",
        "    #Add batch to GPU.\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the inputs from our dataloader.\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    #telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation.\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      # This will return the logits rather than loss because we have not\n",
        "      # provided the labels.\n",
        "      # token_type_ids is same as the \"segment ids\", which differntiates\n",
        "      # sentence 1 and sentence 2 in 2-sentance tasks.\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "      \n",
        "    # Get the 'logits' output from the model. The logits are the output values\n",
        "    # prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    #Move logits and labels to CPU.\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    #Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    # Track the number of batches.\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  print(\" Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(\" validation took: {:}\".format(format_time(time.time() - t0))) \n",
        "\n",
        "print(\"\")\n",
        "print(\"Training Completed!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "========== EPOCH 1 / 4 ==========\n",
            "Training.....\n",
            "  Batch   100 of   844  Elasped : 0:01:11.\n",
            "  Batch   200 of   844  Elasped : 0:02:21.\n",
            "  Batch   300 of   844  Elasped : 0:03:30.\n",
            "  Batch   400 of   844  Elasped : 0:04:40.\n",
            "  Batch   500 of   844  Elasped : 0:05:50.\n",
            "  Batch   600 of   844  Elasped : 0:07:00.\n",
            "  Batch   700 of   844  Elasped : 0:08:09.\n",
            "  Batch   800 of   844  Elasped : 0:09:19.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training Epoch took: 0:09:50\n",
            "\n",
            "Running Validation.....\n",
            " Accuracy: 0.95\n",
            " validation took: 0:00:23\n",
            "\n",
            "========== EPOCH 2 / 4 ==========\n",
            "Training.....\n",
            "  Batch   100 of   844  Elasped : 0:01:10.\n",
            "  Batch   200 of   844  Elasped : 0:02:19.\n",
            "  Batch   300 of   844  Elasped : 0:03:29.\n",
            "  Batch   400 of   844  Elasped : 0:04:38.\n",
            "  Batch   500 of   844  Elasped : 0:05:48.\n",
            "  Batch   600 of   844  Elasped : 0:06:57.\n",
            "  Batch   700 of   844  Elasped : 0:08:07.\n",
            "  Batch   800 of   844  Elasped : 0:09:17.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training Epoch took: 0:09:48\n",
            "\n",
            "Running Validation.....\n",
            " Accuracy: 0.95\n",
            " validation took: 0:00:23\n",
            "\n",
            "========== EPOCH 3 / 4 ==========\n",
            "Training.....\n",
            "  Batch   100 of   844  Elasped : 0:01:10.\n",
            "  Batch   200 of   844  Elasped : 0:02:20.\n",
            "  Batch   300 of   844  Elasped : 0:03:29.\n",
            "  Batch   400 of   844  Elasped : 0:04:39.\n",
            "  Batch   500 of   844  Elasped : 0:05:48.\n",
            "  Batch   600 of   844  Elasped : 0:06:58.\n",
            "  Batch   700 of   844  Elasped : 0:08:08.\n",
            "  Batch   800 of   844  Elasped : 0:09:17.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training Epoch took: 0:09:48\n",
            "\n",
            "Running Validation.....\n",
            " Accuracy: 0.95\n",
            " validation took: 0:00:23\n",
            "\n",
            "========== EPOCH 4 / 4 ==========\n",
            "Training.....\n",
            "  Batch   100 of   844  Elasped : 0:01:10.\n",
            "  Batch   200 of   844  Elasped : 0:02:19.\n",
            "  Batch   300 of   844  Elasped : 0:03:29.\n",
            "  Batch   400 of   844  Elasped : 0:04:38.\n",
            "  Batch   500 of   844  Elasped : 0:05:48.\n",
            "  Batch   600 of   844  Elasped : 0:06:58.\n",
            "  Batch   700 of   844  Elasped : 0:08:07.\n",
            "  Batch   800 of   844  Elasped : 0:09:17.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training Epoch took: 0:09:47\n",
            "\n",
            "Running Validation.....\n",
            " Accuracy: 0.95\n",
            " validation took: 0:00:23\n",
            "\n",
            "Training Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iqmRInzeuTI",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at our training loss over all batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeHYMedbBRNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "0ee66627-8b90-47f9-95e2-515cf74560df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')  \n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "#Label the plot.\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}