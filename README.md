# ü§ñ‚ö° My Natural Language Processing Notebooks
[![](https://img.shields.io/badge/Nakshatra-Singh-brightgreen.svg?colorB=ff0000)](https://nakshatrasinghh-io.vercel.app/) [![](https://img.shields.io/hexpm/l/plug)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/LICENSE)

Made with ‚ù§Ô∏è by Nakshatra Singh.

Connect with me on [LinkedIn](https://www.linkedin.com/in/nakshatrasinghh/).

Please do ‚≠ê the repository, if it helped you in anyway.

If you want to build something together, feel free to email me at - nakshatradsu@gmail.com üìß.

üëâ If you like my work, check out my other [Repositories!](https://github.com/nakshatrasinghh?tab=repositories) üëà

All my Notebooks run without downloading any datasets (Thanks to gdown). Just click, Learn and Explore üî≠ü§ó.

Click <img src="https://colab.research.google.com/assets/colab-badge.svg" align="top"> to view the **Jupyter notebook** in Google Colab:

\# | Description | Link
--- | --- | ---
01 | [How to create a Custom Dataset using Google Play Apps Scrapper script for Sentiment Analysis](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Custom_Dataset_Sentiment.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Custom_Dataset_Sentiment.ipynb)
02 | [Do Pretrained Embeddings really give you an edge in Training NLP Models? (GloVe, Fasttext and Baseline Comparison)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Do_Embeddings_Give_You_An_Edge.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Do_Embeddings_Give_You_An_Edge.ipynb)
03 | [Fake News Detection using Simple Recurrent Neural Network (RNN) and NLTK (Tensorflow)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Fake_News_Detection%2BRNN.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Fake_News_Detection%2BRNN.ipynb)
04 | [Introduction to BERT with Ktrain using IMDB Movie Review Sentiment dataset](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/KTrain%2BBERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/KTrain%2BBERT.ipynb)
05 | [English to Danish Machine Translation using Gated Recurrent Unit (GRU)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Machine_Translation_using_GRUs.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Machine_Translation_using_GRUs.ipynb)
06 | [Question Answering with a Fine-Tuned BERT trained on Stanford Question Answering Dataset (SQuAD)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Question_Answering_with_BERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Question_Answering_with_BERT.ipynb)
07 | [Building a BERT model for Sentiment Analysis using Custom Google Play Apps Reviews Dataset (Pytorch)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Sentiment_Analysis_with_BERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Sentiment_Analysis_with_BERT.ipynb)
08 | [Building a BERT model for Text Classification using IMDB Reviews Dataset (Tensorflow)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Text_Classification_BERT%2BTF.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Text_Classification_BERT%2BTF.ipynb)
09 | [Classifying Toxic Comments with BERT using Jigsaw Toxic Comment Classification Dataset (Pytorch)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Toxic_Comment_Classification%2BBERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Toxic_Comment_Classification%2BBERT.ipynb)
10 | [Disaster Tweets Classification with SVM and BERT with Exploratory Data Analysis](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Disaster_Tweets_Classification_with_SVM_and_BERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Disaster_Tweets_Classification_with_SVM_and_BERT.ipynb)
11 | [Email Spam Detection using Multinomial Naive Bayes Algorithm and CountVectorizer (BOW)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Email_Spam_Detection.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Email_Spam_Detection.ipynb)
12 | [SMS Spam Detection using 7 Differnt Machine Learning Algorithms, and CountVectorizer (BOW)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Spam_Detection_with_7_ML_Algorithms.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Spam_Detection_with_7_ML_Algorithms.ipynb)
13 | [StackOverFlow Tag Prediction using Logistic Regression, OneVsRestClassifer, and MultiLabelBinarizer with Jaccard Score as Evaluation Metric](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Multi_Label_Text_Classification.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Multi_Label_Text_Classification.ipynb)
14 | [MultiLabel Toxic Comments Classification with DistilBERT using Jigsaw Toxic Comment Classification Dataset (Pytorch)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/MutliLabel_Toxic_Comment_Classification.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/MutliLabel_Toxic_Comment_Classification.ipynb)
15 | [Quora Duplicate Questions Detection using Siamese Neural Network, Triplet Loss Function, and Trax](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Duplicate_Question_Recognition.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Duplicate_Question_Recognition.ipynb)
16 | [Urdu Sentiment Classification using Transformers and MultiLingual BERT Model by Hugging Face (Pytorch)](https://github.com/nakshatrasinghh/Natural-Language-Processing/blob/master/Urdu_Sentiment_using_MultiLingual_BERT.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakshatrasinghh/Natural-Language-Processing/blob/master/Urdu_Sentiment_using_MultiLingual_BERT.ipynb)


# üëæPyTorch
PyTorch-Transformers (formerly known as pytorch-pretrained-bert) is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP)
The library currently contains PyTorch implementations, pre-trained model weights, usage scripts and conversion utilities for the following models:
- [BERT](https://github.com/google-research/bert) (from Google) released with the paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova
- [GPT](https://github.com/openai/finetune-transformer-lm) (from OpenAI) released with the paper [Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/) by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever
- [GPT-2](https://blog.openai.com/better-language-models/) (from OpenAI) released with the paper [Language Models are Unsupervised Multitask Learners[(https://blog.openai.com/better-language-models/) by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.
- [Transformer-XL](https://github.com/kimiyoung/transformer-xl) (from Google/CMU) released with the paper [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov
- [XLNet](https://github.com/zihangdai/xlnet/) (from Google/CMU) released with the paper [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le
- [XLM](https://github.com/facebookresearch/XLM/) (from Facebook) released together with the paper [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) by Guillaume Lample and Alexis Conneau
![]()

# Message Me
If you have any doubts feel free to click on the social icon you would like to connect with ü§ó
<p align="left">
<a href="https://medium.com/@nakshatradsml"><img height="42" src="https://user-images.githubusercontent.com/53419293/96714013-27a8fe80-13bf-11eb-892b-eb859e66cd2b.png?raw=true"></a>&nbsp;&nbsp;
<a href="https://www.linkedin.com/in/nakshatrasinghh/"><img height="42" src="https://user-images.githubusercontent.com/53419293/96712764-3e4e5600-13bd-11eb-81e6-50b8c7ea07eb.png?raw=true"></a>&nbsp;&nbsp;
<a href="https://nakshatrasinghh-io.vercel.app/"><img height="42" src="https://user-images.githubusercontent.com/53419293/96724683-bf154e00-13cd-11eb-805e-464c73b45316.png?raw=true"></a>&nbsp;&nbsp;
<a href="https://github.com/nakshatrasinghh"><img height="42" src="https://user-images.githubusercontent.com/53419293/96712562-f7606080-13bc-11eb-86dd-b91470be7b55.png?raw=true"></a>&nbsp;&nbsp;
<a href="https://www.snapchat.com/add/nxkshxtrx.singh"><img height="42" src="https://user-images.githubusercontent.com/53419293/96713786-c41ed100-13be-11eb-9c21-f4d3b0c36220.png?raw=true"></a>&nbsp;&nbsp;
<a href="https://wa.link/8bt67v"><img height="42" src="https://user-images.githubusercontent.com/53419293/96714143-59ba6080-13bf-11eb-8f52-3123014be2da.png?raw=true"></a>&nbsp;&nbsp;
</p>
