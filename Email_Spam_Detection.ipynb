{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email Spam Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBBfM3wYj1hX",
        "colab_type": "text"
      },
      "source": [
        "##*Email Spam Detection Using Multinomial Naive Bayes Algorithm and Simple Bag of Words*\n",
        "\n",
        "By Nakshatra Singh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JF-FFCkvK-",
        "colab_type": "text"
      },
      "source": [
        "###**1. Retrieve and Inspect Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y6I-zEDkybM",
        "colab_type": "text"
      },
      "source": [
        "Let's download the dataset which is uploaded on my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zHLvt7r0meB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1175d981-f828-4c3a-ee01-27feeb9be2f6"
      },
      "source": [
        "!gdown --id 1CLmJed0Qu6DxKChYzAo1iU4ZtT0EO47- "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CLmJed0Qu6DxKChYzAo1iU4ZtT0EO47-\n",
            "To: /content/emails.csv\n",
            "\r0.00B [00:00, ?B/s]\r8.95MB [00:00, 78.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjFmjKPKk0EM",
        "colab_type": "text"
      },
      "source": [
        "We'll use `pandas` to parse the csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r0xcvBKb-F1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "847daaf5-3b07-4653-b5d9-4aedfe831eeb"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/emails.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phcfMJWRk3p8",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the first few rows of the table just to see what's in there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm6x-8M6k7Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738GlyTfk995",
        "colab_type": "text"
      },
      "source": [
        "What's the shape of the dataframe?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34p8daQgcGlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d63bb53d-22af-4f0d-bd06-102f108a0a59"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5728, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MajtSYC4lEfW",
        "colab_type": "text"
      },
      "source": [
        "Does the dataframe contain any null row values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSxi-4j0cI5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a7a8e0d4-c154-4c8f-8906-a427b5ea476c"
      },
      "source": [
        "df.isnull().sum() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOdJEi8wlLcH",
        "colab_type": "text"
      },
      "source": [
        "How many columns does the dataframe have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFXqvuOycK-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e463aec3-6f75-45b0-9ceb-67b352f5e565"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'spam'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWOOtqzPlOpt",
        "colab_type": "text"
      },
      "source": [
        "We'll drop the duplicate texts and check if any rows were dropped or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsFDGsPHcNjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop_duplicates(inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fTwBYC4lW6q",
        "colab_type": "text"
      },
      "source": [
        "Did the shape reduce?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI5uuFIIcRKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34ef7fea-8336-46ec-b71b-ff28c7951343"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5695, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-aHTSA9la2M",
        "colab_type": "text"
      },
      "source": [
        "Yes, this means their were a few duplicate text rows which are now deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiukDXiEl1pg",
        "colab_type": "text"
      },
      "source": [
        "###**2. NLTK**\n",
        "\n",
        "We'll use nltk stopwords to remove words which provide  us no valuable information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COmCcJZ1cR_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4d5e11b5-e95d-42b3-cdc6-dd422866f9de"
      },
      "source": [
        "import nltk \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZdjzX1wmZlN",
        "colab_type": "text"
      },
      "source": [
        "Next, I'll write a helper fuction which will preprocess our text for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYRpr5hicbNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def process_text(text):\n",
        "  # Remove Punctuation\n",
        "  nopunc = [char for char in text if char not in string.punctuation]\n",
        "  nopunc = ''.join(nopunc) \n",
        "  \n",
        "  # Remove Stopwords\n",
        "  clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "  # Return a list of cleaned Text\n",
        "  return clean_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXFp6vQKmjUI",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the dataframe looks after applying the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjRRaxajdWo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "31aa2f93-ed2b-44f9-bbea-2e9f0f1c23ad"
      },
      "source": [
        "df['text'].head().apply(process_text) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Subject, naturally, irresistible, corporate, ...\n",
              "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2    [Subject, unbelievable, new, homes, made, easy...\n",
              "3    [Subject, 4, color, printing, special, request...\n",
              "4    [Subject, money, get, software, cds, software,...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBa6kIpmqnYs",
        "colab_type": "text"
      },
      "source": [
        "###**3. Further Understanding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8X8f2BSmsjY",
        "colab_type": "text"
      },
      "source": [
        "Here is an example of how Bag of Words makes a matrix of count features for each word present in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LktaidLsd0gK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "08c55b9a-d3ca-4e4e-ca3d-f85ed242587b"
      },
      "source": [
        "# Example\n",
        "\n",
        "message4 = 'hello hello hello world hello play'\n",
        "message5 = 'test test test one hello hello world'\n",
        "print(message4) \n",
        "\n",
        "# Convert the text to a matrix of token counts\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow4 = CountVectorizer(analyzer=process_text).fit_transform([[message4], [message5]])\n",
        "print(bow4)          # Matrix of Features\n",
        "print()\n",
        "print(bow4.shape)    # Matrix Space of token counts\n",
        "\n",
        "# 0 at the first index means first sentence and 1 at the first index means\n",
        "# second sentence.\n",
        "# --> (0, 0) == first sentence, (a particular word is given a random index [i], hello is given the index 0)\n",
        "# which is repeated 4 times in that sentence only."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello hello hello world hello play\n",
            "  (0, 0)\t4\n",
            "  (0, 4)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 0)\t2\n",
            "  (1, 4)\t1\n",
            "  (1, 3)\t3\n",
            "  (1, 1)\t1\n",
            "\n",
            "(2, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Pv7Y7SowiK",
        "colab_type": "text"
      },
      "source": [
        "Let's convert all our text in the dataframe to a bag of words matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB3xjJeyemBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert a collection of text to a matrix of tokens\n",
        "message_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPVGRdGo4dv",
        "colab_type": "text"
      },
      "source": [
        "Let's see how many unique tokens (without stopwords) are made by CountVectroizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKgktMj5gVq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50ad8f76-5660-4862-eaf9-96a7590f94ad"
      },
      "source": [
        "message_bow.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5695, 37229)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_K5Mw_pB_2",
        "colab_type": "text"
      },
      "source": [
        "Let's split the data into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kAaK-MsfyU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, x_validation, Y_train, y_validation = train_test_split(message_bow,\n",
        "                                                                df['spam'], \n",
        "                                                                test_size=0.2,\n",
        "                                                                random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTnzIpr9quQK",
        "colab_type": "text"
      },
      "source": [
        "###**4. Multinomial Naive Bayes Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBhBdygpQA5",
        "colab_type": "text"
      },
      "source": [
        "We'll use the Multinomial Naive Bayes classifier, as it is good in handling mutiple features and will suit this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeiLcD4QgWtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB().fit(X_train, Y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57MxkBmWptDD",
        "colab_type": "text"
      },
      "source": [
        "Now, let's have a quick glimpse if our model is doing alright or now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNdHxUaxgnLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "030c9b98-c22c-4e35-af8b-5a44047126d5"
      },
      "source": [
        "print(classifier.predict(X_train))\n",
        "\n",
        "print(Y_train.values) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2d5YHm0py0F",
        "colab_type": "text"
      },
      "source": [
        "We aren't able to see much of the target columns (due to big size) but the classifier gives correct predictions for the most of it as we see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpUBPPVCqz8F",
        "colab_type": "text"
      },
      "source": [
        "###**5. Model Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOxlcWytqBhs",
        "colab_type": "text"
      },
      "source": [
        "Now since our model is trained, let's print out the model metrics which will define how good our model is actually doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL6zXQn9g4-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "c7bf5364-5cd7-4dd4-e935-7d9b40aba51f"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# On Training data\n",
        "y_pred = classifier.predict(X_train)\n",
        "print(classification_report(Y_train, y_pred))       # Classification Report\n",
        "print()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(Y_train, y_pred)) # Confusion Matrix\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(Y_train, y_pred)) # Accuracy Score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3457\n",
            "           1       0.99      1.00      0.99      1099\n",
            "\n",
            "    accuracy                           1.00      4556\n",
            "   macro avg       0.99      1.00      1.00      4556\n",
            "weighted avg       1.00      1.00      1.00      4556\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3445   12]\n",
            " [   1 1098]]\n",
            "\n",
            "Accuracy:  0.9971466198419666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sa2UDcqhHwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "d274a2a3-f050-4903-f701-76aa7e818d18"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# On Validation Data\n",
        "y_pred = classifier.predict(x_validation)\n",
        "print(classification_report(y_validation, y_pred))\n",
        "print()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_validation, y_pred)) \n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_validation, y_pred))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       870\n",
            "           1       0.97      1.00      0.98       269\n",
            "\n",
            "    accuracy                           0.99      1139\n",
            "   macro avg       0.98      0.99      0.99      1139\n",
            "weighted avg       0.99      0.99      0.99      1139\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[862   8]\n",
            " [  1 268]]\n",
            "\n",
            "Accuracy:  0.9920983318700615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orv1PuWgq-M_",
        "colab_type": "text"
      },
      "source": [
        "###**6. Summary**\n",
        "\n",
        "- We understood how bag of word works\n",
        "- We saw how a simple CountVectorzier with MultinomialNB can give extremely accurate results.\n",
        "- We used NLTK stopwords to remove unnecessary words which dont give us much information.\n",
        "- We also evaluated the model metrics for performance.\n",
        "\n",
        "IF YOU LIKED THIS NOTEBOOK, MAKE SURE TO CHECK OUT MY OTHER [REPOSðŸ‘Š](https://github.com/nakshatrasinghh?tab=repositories)!!!"
      ]
    }
  ]
}
